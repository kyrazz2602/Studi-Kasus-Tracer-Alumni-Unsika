# -*- coding: utf-8 -*-
"""Studi Kasus: Tracer Alumni UNSIKA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yjJVIiroM1st95uD3JHZhmmci2eXnl0S

# **Inisiasi Data**

## **Menentukan Tujuan & Ruang Lingkup**

Merumuskan tujuan utama proyek tracer
alumni, termasuk informasi yang
dibutuhkan untuk pengembangan
akademik dan parameter keberhasilan
proyek.

## **Identifikasi Stakeholder**

Memetakan semua pemangku
kepentingan yang terlibat dalam proyek,
termasuk fakultas, program studi, bagian
kemahasiswaan, dan mitra industri.

## **Menyusun Timeline**

Membuat jadwal terperinci dengan
milestone untuk setiap fase proyek,
termasuk tenggat waktu dan alokasi
sumber daya.

# **Persiapan Data**
"""

pip install pandas Faker

"""# **Import Library**"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from scipy.stats import chi2_contingency
import statsmodels.api as sm
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

"""## **Membuat Dummy Dataset**"""

import pandas as pd
import faker
import random
import re

# Inisialisasi Faker untuk data Indonesia
fake = faker.Faker('id_ID')

# --- KONFIGURASI DATASET ---
JUMLAH_DATA = 350
PROGRAM_STUDI = "Teknik Elektro"
DOMISILI_OPSI = ['Karawang', 'Cikarang', 'Bekasi', 'Jakarta']
KONSENTRASI_OPSI = ["Teknik Tenaga Listrik (Arus Kuat)", "Teknik Elektronika (Arus Lemah)", "Teknik Telekomunikasi", "Teknik Kendali dan Instrumentasi", "Teknik Komputer"]
LOKASI_KERJA_OPSI = ['Jakarta', 'Bandung', 'Surabaya', 'Medan', 'Makassar', 'Karawang', 'Yogyakarta', 'Semarang', 'Batam']

# Data pool untuk membuat data lebih realistis
INDUSTRI_PERUSAHAAN = {
    'Energi': {
        'BUMN': ['PT PLN (Persero)', 'PT Pertamina Geothermal Energy', 'PT Pembangkitan Jawa-Bali'],
        'Multinasional': ['Schneider Electric', 'Siemens Energy', 'General Electric'],
        'Swasta Nasional': ['PT Adaro Energy', 'PT Medco Energi']
    },
    'Telekomunikasi': {
        'BUMN': ['PT Telkom Indonesia', 'PT Telkomsel'],
        'Multinasional': ['Huawei Indonesia', 'Ericsson Indonesia', 'Nokia Solutions'],
        'Swasta Nasional': ['PT Indosat Tbk', 'PT XL Axiata Tbk']
    },
    'Manufaktur': {
        'Multinasional': ['PT Astra Honda Motor', 'PT Toyota Motor Manufacturing', 'Samsung Electronics Indonesia'],
        'Swasta Nasional': ['PT Mayora Indah Tbk', 'PT Indofood CBP Sukses Makmur']
    },
    'IT': {
        'Startup': ['GoTo (Gojek Tokopedia)', 'Traveloka', 'Bukalapak'],
        'Multinasional': ['Google Indonesia', 'Microsoft Indonesia', 'IBM Indonesia'],
        'Konsultan': ['Accenture', 'Deloitte Consulting']
    },
    'Otomotif': {
        'Multinasional': ['PT Hyundai Motors Indonesia', 'PT Mitsubishi Motors Krama Yudha'],
        'Swasta Nasional': ['PT Astra Otoparts Tbk']
    },
    'Elektronik': {
        'Multinasional': ['PT LG Electronics Indonesia', 'Panasonic Manufacturing Indonesia'],
        'Swasta Nasional': ['PT Hartono Istana Teknologi (Polytron)']
    }
}

POSISI_JABATAN = {
    'Teknik Tenaga Listrik (Arus Kuat)': ['Power System Engineer', 'Electrical Maintenance Supervisor', 'Project Engineer', 'HSE Officer'],
    'Teknik Elektronika (Arus Lemah)': ['Electronics Engineer', 'Hardware Design Engineer', 'PCB Layout Designer', 'Test Engineer'],
    'Teknik Telekomunikasi': ['Network Engineer', 'RF (Radio Frequency) Engineer', 'Core Network Specialist', 'Field Engineer'],
    'Teknik Kendali dan Instrumentasi': ['Control System Engineer', 'Instrumentation Engineer', 'Automation & Robotics Engineer', 'PLC Programmer'],
    'Teknik Komputer': ['Data Analyst', 'Data Sientist', 'AI Engineer', 'Machine Learning Engineer', 'IT Support Specialist', 'Firmware Engineer', 'System Administrator']
}

KETERAMPILAN_TAMBAHAN = [
    'AWS Certified Cloud Practitioner', 'PLC Programming (Siemens/Allen-Bradley)', 'Python for Data Science',
    'TOEFL > 550', 'CCNA (Cisco Certified Network Associate)', 'Project Management Professional (PMP)',
    'MikroTik MTCNA', 'Data Visualization (Tableau)', 'Certified Ethical Hacker (CEH)'
]

UMPAN_BALIK = [
    'Perbanyak praktikum IoT dan embedded system.', 'Tambahkan mata kuliah tentang machine learning.',
    'Kurikulum perlu lebih fokus pada energi terbarukan dan smart grid.', 'Kerja sama industri untuk program magang perlu ditingkatkan.',
    'Materi telekomunikasi 5G dan teknologi nirkabel perlu diperbarui.', 'Tingkatkan workshop tentang soft skills dan manajemen proyek.',
    'Perlu ada mata kuliah pilihan tentang kendaraan listrik (EV).', 'Sertifikasi keahlian (misal: PLC) sebaiknya diintegrasikan dalam kurikulum.'
]

# --- FUNGSI UNTUK MENGHASILKAN DATA ---
def generate_dataset(n_rows):
    data_alumni = []
    for i in range(n_rows):
        # 1. Data Pribadi & Akademik
        nama = fake.name()
        domisili = random.choice(DOMISILI_OPSI)
        tahun_angkatan = random.randint(2016, 2024)
        konsentrasi = random.choice(KONSENTRASI_OPSI)

        # Buat email dummy yang konsisten
        nama_clean = re.sub(r'\W+', '', nama.lower().replace(" ", "."))
        email = f"{nama_clean}{str(tahun_angkatan)[-2:]}@email.com"

        # 2. Informasi Karir (saling terkait)
        bidang_industri = random.choice(list(INDUSTRI_PERUSAHAAN.keys()))
        tipe_perusahaan = random.choice(list(INDUSTRI_PERUSAHAAN[bidang_industri].keys()))
        perusahaan = random.choice(INDUSTRI_PERUSAHAAN[bidang_industri][tipe_perusahaan])
        posisi = random.choice(POSISI_JABATAN[konsentrasi])
        lokasi_geografis = random.choice(LOKASI_KERJA_OPSI)

        # 3. Gaji (tergantung tahun angkatan dan tipe perusahaan)
        gaji_dasar = 4000000
        # Kenaikan gaji berdasarkan pengalaman (tahun lulus)
        pengalaman = 2025 - (tahun_angkatan + 4) # Asumsi lulus 4 tahun
        kenaikan_per_tahun = random.randint(500000, 1200000)
        gaji = gaji_dasar + (pengalaman * kenaikan_per_tahun)
        # Penyesuaian berdasarkan tipe perusahaan
        if tipe_perusahaan == 'Multinasional':
            gaji *= 1.4
        elif tipe_perusahaan == 'BUMN':
            gaji *= 1.2
        elif tipe_perusahaan == 'Startup':
            gaji *= 1.1
        gaji = min(max(gaji, 4000000), 25000000) # Batasi gaji dalam rentang
        gaji = round(gaji / 100000) * 100000 # Bulatkan ke ratusan ribu terdekat

        # 4. Data Tambahan
        relevansi_kurikulum = round(random.uniform(2.5, 5.0), 1)
        keterampilan_tambahan = ", ".join(random.sample(KETERAMPILAN_TAMBAHAN, k=random.randint(1, 3)))
        umpan_balik = random.choice(UMPAN_BALIK)

        data_alumni.append({
            'Nama': nama,
            'Domisili': domisili,
            'Tahun Angkatan': tahun_angkatan,
            'Program Studi': PROGRAM_STUDI,
            'Konsentrasi': konsentrasi,
            'Informasi Kontak': email,
            'Perusahaan': perusahaan,
            'Posisi/Jabatan': posisi,
            'Bidang Industri': bidang_industri,
            'Gaji': int(gaji),
            'Lokasi Geografis': lokasi_geografis,
            'Relevansi Kurikulum': relevansi_kurikulum,
            'Keterampilan Tambahan': keterampilan_tambahan,
            'Umpan Balik': umpan_balik
        })
    return data_alumni

# --- EKSEKUSI DAN SIMPAN FILE ---
if __name__ == "__main__":
    dataset = generate_dataset(JUMLAH_DATA)
    df = pd.DataFrame(dataset)

    # Simpan ke file CSV
    nama_file_csv = 'tracer_alumni_elektro_unsika.csv'
    df.to_csv(nama_file_csv, index=False, encoding='utf-8')

    print(f"✅ Dataset dummy berhasil dibuat!")
    print(f"Jumlah data: {len(df)} baris")
    print(f"File disimpan sebagai: '{nama_file_csv}'")
    print("\n--- Contoh 5 Baris Data Pertama ---")
    print(df.head().to_string())

"""## **Proses Indentifikasi Data**"""

# 1. Tampilkan informasi dasar tentang DataFrame
print("-- Informasi Dasar DataFrame --")
df.info()
print("\n--- Statistik Deskriptif Data Numerik ---")
display(df.describe())
print("\n--- Statistik Deskriptif Data Kategorikal ---")
display(df.describe(include='object'))

"""## **Proses Membersihkan Data**

### Menghapus Duplikasi
"""

# 2. Hapus duplikasi baris data
initial_rows = len(df)
df.drop_duplicates(inplace=True)
rows_after_dropping_duplicates = len(df)
print(f"\n--- Penanganan Duplikasi ---")
print(f"Jumlah baris sebelum dihapus duplikasi: {initial_rows}")
print(f"Jumlah baris setelah dihapus duplikasi: {rows_after_dropping_duplicates}")
print(f"Jumlah duplikasi yang dihapus: {initial_rows - rows_after_dropping_duplicates}")

"""### Memperbaiki Penulisan pada data"""

# 3. Perbaiki kesalahan penulisan pada kolom teks (typos)
typo_corrections = {
    'Domisili': {'Jakrta': 'Jakarta', 'Bandug': 'Bandung'},
    'Lokasi Geografis': {'Jakrta': 'Jakarta', 'Bandug': 'Bandung'}
}

print("\n--- Perbaikan Typo ---")
for column, corrections in typo_corrections.items():
    if column in df.columns:
        initial_unique = df[column].nunique()
        df[column] = df[column].replace(corrections)
        after_correction_unique = df[column].nunique()
        print(f"Kolom '{column}': Jumlah nilai unik sebelum perbaikan typo = {initial_unique}, setelah perbaikan = {after_correction_unique}")
    else:
        print(f"Kolom '{column}' tidak ditemukan dalam DataFrame.")

"""### Menangani Missing Values"""

# 4. Tangani nilai yang hilang (missing values)
print("\n--- Penanganan Missing Values ---")
print("Jumlah missing values sebelum penanganan:")
print(df.isnull().sum())

# Imputasi untuk kolom numerik
numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in numeric_cols:
    if df[col].isnull().sum() > 0:
        if col in ['Tahun Angkatan', 'Gaji', 'Relevansi Kurikulum']: # Kolom yang ingin diisi dengan median/mean
             median_val = df[col].median()
             df[col].fillna(median_val, inplace=True)
             print(f"Missing values di '{col}' diisi dengan median ({median_val})")

# Imputasi untuk kolom kategorikal
categorical_cols = df.select_dtypes(include='object').columns
for col in categorical_cols:
    if df[col].isnull().sum() > 0:
        if col in ['Domisili', 'Konsentrasi', 'Perusahaan', 'Posisi/Jabatan', 'Bidang Industri', 'Lokasi Geografis', 'Keterampilan Tambahan', 'Umpan Balik']: # Kolom yang ingin diisi dengan modus
            mode_val = df[col].mode()[0] # mode() bisa mengembalikan multiple, ambil yang pertama
            df[col].fillna(mode_val, inplace=True)
            print(f"Missing values di '{col}' diisi dengan modus ('{mode_val}')")

print("\nJumlah missing values setelah penanganan:")
print(df.isnull().sum())

"""### Menyamakan Format Data"""

# 5. Samakan format data
print("\n--- Penyeragaman Format Data ---")

# Tahun Angkatan: pastikan integer
if 'Tahun Angkatan' in df.columns:
    df['Tahun Angkatan'] = pd.to_numeric(df['Tahun Angkatan'], errors='coerce').astype('Int64') # Use Int64 to allow NaN
    print("Format 'Tahun Angkatan' diseragamkan menjadi integer.")

# Lokasi Geografis & Domisili: kapital awal
if 'Lokasi Geografis' in df.columns:
    df['Lokasi Geografis'] = df['Lokasi Geografis'].str.capitalize()
    print("Format 'Lokasi Geografis' diseragamkan (kapital awal).")
if 'Domisili' in df.columns:
    df['Domisili'] = df['Domisili'].str.capitalize()
    print("Format 'Domisili' diseragamkan (kapital awal).")

# Gaji: pastikan integer tanpa simbol
if 'Gaji' in df.columns:
    # Hapus karakter non-digit kecuali koma/titik jika ada, lalu konversi ke numerik
    df['Gaji'] = df['Gaji'].astype(str).str.replace(r'[^\d]', '', regex=True)
    df['Gaji'] = pd.to_numeric(df['Gaji'], errors='coerce')
    # Isi NaN yang mungkin muncul karena konversi gagal setelah pembersihan
    if df['Gaji'].isnull().sum() > 0:
        median_gaji = df['Gaji'].median()
        df['Gaji'].fillna(median_gaji, inplace=True)
        print(f"Missing values yang muncul setelah pembersihan format 'Gaji' diisi dengan median ({median_gaji})")
    df['Gaji'] = df['Gaji'].astype(int)
    print("Format 'Gaji' diseragamkan menjadi integer tanpa simbol.")

# Relevansi Kurikulum: pastikan skala 1-5 dan float
if 'Relevansi Kurikulum' in df.columns:
    df['Relevansi Kurikulum'] = pd.to_numeric(df['Relevansi Kurikulum'], errors='coerce')
    # Batasi nilai antara 1 dan 5
    df['Relevansi Kurikulum'] = df['Relevansi Kurikulum'].clip(lower=1, upper=5)
    # Isi NaN yang mungkin muncul karena konversi gagal
    if df['Relevansi Kurikulum'].isnull().sum() > 0:
        median_relevansi = df['Relevansi Kurikulum'].median()
        df['Relevansi Kurikulum'].fillna(median_relevansi, inplace=True)
        print(f"Missing values yang muncul setelah pembersihan format 'Relevansi Kurikulum' diisi dengan median ({median_relevansi})")
    print("Format 'Relevansi Kurikulum' diseragamkan (skala 1-5, float).")

"""### Menghapus Outlier pada data"""

# 6. Hapus outlier tidak wajar pada Gaji
if 'Gaji' in df.columns:
    initial_rows_outlier = len(df)
    df = df[(df['Gaji'] >= 2000000) & (df['Gaji'] <= 100000000)].copy() # Use .copy() to avoid SettingWithCopyWarning
    rows_after_removing_outliers = len(df)
    print(f"\n--- Penanganan Outlier Gaji ---")
    print(f"Jumlah baris sebelum hapus outlier: {initial_rows_outlier}")
    print(f"Jumlah baris setelah hapus outlier: {rows_after_removing_outliers}")
    print(f"Jumlah outlier yang dihapus: {initial_rows_outlier - rows_after_removing_outliers}")

# 7. Tampilkan dataset yang sudah bersih dan siap dianalisis
print("\n--- DataFrame Setelah Data Cleaning ---")
display(df.head())
print("\n--- Informasi DataFrame Setelah Data Cleaning ---")
df.info()

# 2. Profil Alumni
print("Distribusi Tahun Angkatan:\n", df['Tahun Angkatan'].value_counts())
print("\nDistribusi Konsentrasi:\n", df['Konsentrasi'].value_counts())

sns.countplot(data=df, x="Tahun Angkatan")
plt.title("Distribusi Alumni per Tahun Angkatan")
plt.xticks(rotation=45)
plt.show()

# 1. Hitung jumlah alumni per konsentrasi studi
alumni_per_konsentrasi = df['Konsentrasi'].value_counts()

# 2. Buat diagram lingkaran untuk konsentrasi
plt.figure(figsize=(10, 8))
plt.pie(alumni_per_konsentrasi, labels=alumni_per_konsentrasi.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('viridis', len(alumni_per_konsentrasi)))
plt.title('Proporsi Alumni per Konsentrasi Studi', fontsize=16)
plt.axis('equal') # Equal aspect ratio ensures that pie is drawn as a circle.
plt.legend(title="Konsentrasi", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))
plt.tight_layout()
plt.show()

# 1. Hitung jumlah alumni per bidang industri
alumni_per_industri = df['Bidang Industri'].value_counts()

# 2. Buat grafik batang horizontal untuk menampilkan distribusi alumni per bidang industri
plt.figure(figsize=(12, 8))
sns.barplot(x=alumni_per_industri.values, y=alumni_per_industri.index, palette='viridis')
plt.title('Distribusi Alumni per Bidang Industri', fontsize=16)
plt.xlabel('Jumlah Alumni', fontsize=12)
plt.ylabel('Bidang Industri', fontsize=12)
plt.tight_layout()
plt.show()

# 3. Hitung jumlah alumni per posisi
alumni_per_posisi = df['Posisi/Jabatan'].value_counts()

# 4. Buat grafik batang horizontal untuk menampilkan distribusi alumni per posisi
plt.figure(figsize=(12, 10))
sns.barplot(x=alumni_per_posisi.values, y=alumni_per_posisi.index, palette='viridis')
plt.title('Distribusi Alumni per Posisi', fontsize=16)
plt.xlabel('Jumlah Alumni', fontsize=12)
plt.ylabel('Posisi', fontsize=12)
plt.tight_layout()
plt.show()

# 5. Perusahaan & Posisi
print("\nTop 10 Perusahaan Alumni:\n", df['Perusahaan'].value_counts().head(10))
print("\nTop 10 Posisi Alumni:\n", df['Posisi/Jabatan'].value_counts().head(10))

# 6. Distribusi Gaji
plt.figure(figsize=(8,6))
sns.boxplot(data=df, x="Bidang Industri", y="Gaji")
plt.xticks(rotation=45)
plt.title("Distribusi Gaji Alumni per Bidang Industri")
plt.show()

# 4. Sebaran Geografis
alumni_lokasi = df['Lokasi Geografis'].value_counts().reset_index()
alumni_lokasi.columns = ["Provinsi", "Jumlah Alumni"]

fig = px.choropleth(
    alumni_lokasi,
    geojson="https://raw.githubusercontent.com/superpikar/indonesia-geojson/master/indonesia-province.json",
    featureidkey="properties.Propinsi",
    locations="Provinsi",
    color="Jumlah Alumni",
    color_continuous_scale="Viridis",
    title="Sebaran Alumni per Provinsi"
)
fig.update_geos(fitbounds="locations", visible=False)
fig.show()

"""## Summary:

### Data Analysis Key Findings

*   The average alumni salary is approximately Rp 6.36 million with significant variation.
*   There is a statistically significant negative relationship between GPA and the job waiting period (P-value < 0.0001), indicating that higher GPAs are associated with shorter waiting times for employment.
*   A statistically significant relationship exists between internship experience and job placement (P-value < 0.0001), highlighting the importance of internships.
*   No statistically significant relationship was found between study concentration and the industry field where alumni work (P-value 0.8178).
*   There was no statistically significant difference in average salary based on participation in extracurricular activities (P-value 0.9926) or geographical location (P-value 0.0640) in this dataset.
*   Cluster analysis identified distinct alumni segments based on numerical features like salary and graduation year.
*   Sentiment analysis on alumni feedback in the dummy data was predominantly neutral (86.57%), with some positive feedback (13.43%) and no negative feedback.

### Insights or Next Steps

*   Focus on strategies to improve student GPA and enhance internship programs, as these show a significant correlation with post-graduation success (shorter waiting period, better placement).
*   Investigate the lack of a significant relationship between study concentration and industry placement further, as this finding is counter-intuitive and may require more detailed data or analysis to understand alumni career paths.

"""

# --- PERSIAPAN DATA: Tambahkan kolom dummy jika belum ada ---

# Tambah IPK
if 'IPK' not in df.columns:
    df['IPK'] = np.random.uniform(2.75, 4.00, size=len(df)).round(2)

# Tambah Masa Tunggu Kerja (simulasi hubungan negatif dengan IPK)
if 'Masa Tunggu Kerja' not in df.columns:
    df['Masa Tunggu Kerja'] = df['IPK'].apply(
        lambda x: max(1, int(random.gauss(12 - (x - 2.75) * 4, 5)))
    )
    df['Masa Tunggu Kerja'] = df['Masa Tunggu Kerja'].clip(upper=36)

# Tambah Aktivitas Ekstrakurikuler
if 'Aktivitas Ekstrakurikuler' not in df.columns:
    df['Aktivitas Ekstrakurikuler'] = np.random.choice(
        ['Aktif', 'Tidak Aktif'], size=len(df), p=[0.6, 0.4]
    )

# Add dummy columns for 'Pengalaman Magang' and 'Penempatan Kerja'
if 'Pengalaman Magang' not in df.columns:
    df['Pengalaman Magang'] = np.random.choice(
        ['Ada', 'Tidak Ada'], size=len(df), p=[0.7, 0.3]
    )

if 'Penempatan Kerja' not in df.columns:
    # Simulate a relationship: alumni with internship are more likely to be placed
    df['Penempatan Kerja'] = df['Pengalaman Magang'].apply(
        lambda x: 'Sudah Ditempatkan' if x == 'Ada' and random.random() < 0.85 else ('Sudah Ditempatkan' if x == 'Tidak Ada' and random.random() < 0.4 else 'Belum Ditempatkan')
    )

# Simpan ke file CSV
nama_file_csv = 'new_tracer_alumni_elektro_unsika.csv'
df.to_csv(nama_file_csv, index=False, encoding='utf-8')

print("--- Struktur DataFrame setelah penambahan kolom dummy ---")
df.info()
display(df.head())

# 2. Analisis deskriptif untuk kolom kategorikal
categorical_cols_desc = ['Konsentrasi', 'Perusahaan', 'Posisi/Jabatan', 'Bidang Industri', 'Lokasi Geografis']

print("\n--- Analisis Deskriptif Kolom Kategorikal ---")
for col in categorical_cols_desc:
    print(f"\nKolom: {col}")
    frequency = df[col].value_counts()
    percentage = df[col].value_counts(normalize=True) * 100
    descriptive_table = pd.DataFrame({'Frequency': frequency, 'Percentage (%)': percentage})
    display(descriptive_table)

descriptive_table_sorted = descriptive_table.sort_values('Percentage (%)', ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x=descriptive_table_sorted.index, y=descriptive_table_sorted['Percentage (%)'], palette='viridis')
plt.title('Persentase Alumni per Lokasi Geografis', fontsize=16)
plt.xlabel('Lokasi Geografis', fontsize=12)
plt.ylabel('Persentase (%)', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""## Analisis korelasi utama

### Subtask:
Hitung dan tampilkan uji Chi-Square untuk menganalisis korelasi antara Konsentrasi studi dan Bidang Industri tempat alumni bekerja.

**Reasoning**:
Calculate and display the Chi-Square test results for the relationship between 'Konsentrasi' and 'Bidang Industri'.
"""

# 1. Buat tabel kontingensi
contingency_table = pd.crosstab(df['Konsentrasi'], df['Bidang Industri'])

# 2. Gunakan fungsi chi2_contingency
chi2_stat, p_value, dof, expected_freq = chi2_contingency(contingency_table)

# 3. Cetak hasil uji Chi-Square
print("\n--- Hasil Uji Chi-Square: Konsentrasi vs Bidang Industri ---")
print(f"Chi-square statistic: {chi2_stat}")
print(f"P-value: {p_value}")
print(f"Degrees of freedom: {dof}")

# 4. Tentukan signifikansi
alpha = 0.05
print(f"\nTingkat signifikansi (alpha): {alpha}")

if p_value < alpha:
    print("Kesimpulan: Terdapat hubungan yang signifikan secara statistik antara Konsentrasi studi dan Bidang Industri (Tolak H0).")
else:
    print("Kesimpulan: Tidak terdapat hubungan yang signifikan secara statistik antara Konsentrasi studi dan Bidang Industri (Gagal Tolak H0).")

# --- Heatmap dari tabel kontingensi ---
plt.figure(figsize=(10,6))
sns.heatmap(contingency_table, annot=True, fmt="d", cmap="Blues")
plt.title("Heatmap Konsentrasi vs Bidang Industri", fontsize=14)
plt.xlabel("Bidang Industri")
plt.ylabel("Konsentrasi Studi")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()
plt.show()

# --- Stacked Bar Chart ---
contingency_table_norm = contingency_table.div(contingency_table.sum(axis=1), axis=0)

contingency_table_norm.plot(kind="bar", stacked=True, figsize=(10,6), colormap="tab20")
plt.title("Distribusi Bidang Industri berdasarkan Konsentrasi Studi", fontsize=14)
plt.xlabel("Konsentrasi Studi")
plt.ylabel("Proporsi (%)")
plt.legend(title="Bidang Industri", bbox_to_anchor=(1.05, 1), loc="upper left")
plt.tight_layout()
plt.show()

"""## Analisis korelasi utama

### Subtask:
Hitung dan tampilkan analisis regresi linier untuk menganalisis hubungan antara Masa Tunggu Kerja (variabel dependen) dan IPK (variabel independen).

**Reasoning**:
Calculate and display the linear regression analysis to analyze the relationship between Job Waiting Period and GPA.
"""

# 1. Definisikan variabel independen (IPK) dan tambahkan konstanta
X_reg = sm.add_constant(df['IPK'])

# 2. Definisikan variabel dependen (Masa Tunggu Kerja)
y_reg = df['Masa Tunggu Kerja']

# 3. Buat model regresi OLS
model = sm.OLS(y_reg, X_reg)

# 4. Fit model ke data
results = model.fit()

# 5. Cetak ringkasan hasil regresi
print("\n--- Hasil Analisis Regresi: Masa Tunggu Kerja vs IPK ---")
print(results.summary())

# --- Scatter Plot dengan Regression Line ---
plt.figure(figsize=(8,6))
sns.scatterplot(x=df['IPK'], y=df['Masa Tunggu Kerja'], alpha=0.7, s=60, color="blue", edgecolor="k")

# Prediksi garis regresi
x_vals = np.linspace(df['IPK'].min(), df['IPK'].max(), 100)
y_pred = results.params[0] + results.params[1] * x_vals
plt.plot(x_vals, y_pred, color="red", linewidth=2, label="Regression Line")

# Tambahkan label & judul
plt.title("Hubungan antara IPK dan Masa Tunggu Kerja", fontsize=14)
plt.xlabel("IPK", fontsize=12)
plt.ylabel("Masa Tunggu Kerja (bulan)", fontsize=12)
plt.legend()
plt.grid(alpha=0.3)
plt.show()

# --- Kesimpulan ---
r_squared = results.rsquared
p_value = results.pvalues[1]  # p-value koefisien IPK
coef = results.params[1]

print("\n--- Kesimpulan Analisis Regresi ---")
print(f"R-squared: {r_squared:.3f}")
print(f"Koefisien IPK: {coef:.3f}")
print(f"P-value: {p_value:.4f}")

alpha = 0.05
if p_value < alpha:
    if coef < 0:
        print("Kesimpulan: Terdapat hubungan signifikan. Semakin tinggi IPK → semakin singkat masa tunggu kerja.")
    else:
        print("Kesimpulan: Terdapat hubungan signifikan. Semakin tinggi IPK → semakin lama masa tunggu kerja.")
else:
    print("Kesimpulan: Tidak terdapat hubungan signifikan antara IPK dan masa tunggu kerja.")

"""**Reasoning**:
Calculate and display the Chi-Square test for the relationship between Internship Experience and Job Placement.


"""

# Create a contingency table for Internship Experience vs Job Placement
contingency_table_internship = pd.crosstab(df['Pengalaman Magang'], df['Penempatan Kerja'])

# Perform the Chi-Square test
chi2_stat_internship, p_value_internship, dof_internship, expected_freq_internship = chi2_contingency(contingency_table_internship)

# Print the results
print("\n--- Hasil Uji Chi-Square: Pengalaman Magang vs Penempatan Kerja ---")
print(f"Chi-square statistic: {chi2_stat_internship}")
print(f"P-value: {p_value_internship}")
print(f"Degrees of freedom: {dof_internship}")

# Determine significance
alpha = 0.05
print(f"\nTingkat signifikansi (alpha): {alpha}")

if p_value_internship < alpha:
    print("Kesimpulan: Terdapat hubungan yang signifikan secara statistik antara Pengalaman Magang dan Penempatan Kerja (Tolak H0).")
else:
    print("Kesimpulan: Tidak terdapat hubungan yang signifikan secara statistik antara Pengalaman Magang dan Penempatan Kerja (Gagal Tolak H0).")

# --- Heatmap ---
plt.figure(figsize=(8,6))
sns.heatmap(contingency_table_internship, annot=True, fmt='d', cmap="YlOrBr")
plt.title("Heatmap: Pengalaman Magang vs Penempatan Kerja")
plt.xlabel("Penempatan Kerja")
plt.ylabel("Pengalaman Magang")
plt.show()

# --- Stacked Bar Chart ---
contingency_table_internship.plot(kind='bar', stacked=True, figsize=(10,6), colormap="plasma")
plt.title("Distribusi Penempatan Kerja berdasarkan Pengalaman Magang")
plt.xlabel("Pengalaman Magang")
plt.ylabel("Jumlah Alumni")
plt.xticks(rotation=45)
plt.legend(title="Penempatan Kerja")
plt.show()

"""## Analisis korelasi utama

### Subtask:
Hitung dan tampilkan uji Chi-Square untuk menganalisis korelasi antara Aktivitas ekstrakurikuler dan status Penempatan kerja alumni.

**Reasoning**:
Create a contingency table for 'Aktivitas Ekstrakurikuler' and 'Penempatan Kerja' and perform the Chi-Square test to analyze their relationship.
"""

# 1. Buat tabel kontingensi untuk Aktivitas Ekstrakurikuler vs Penempatan Kerja
contingency_table_aktivitas = pd.crosstab(df['Aktivitas Ekstrakurikuler'], df['Penempatan Kerja'])

# 2. Lakukan uji Chi-Square
chi2_stat_aktivitas, p_value_aktivitas, dof_aktivitas, expected_freq_aktivitas = chi2_contingency(contingency_table_aktivitas)

# 3. Cetak hasil uji Chi-Square
print("\n--- Hasil Uji Chi-Square: Aktivitas Ekstrakurikuler vs Penempatan Kerja ---")
print(f"Chi-square statistic: {chi2_stat_aktivitas}")
print(f"P-value: {p_value_aktivitas}")
print(f"Degrees of freedom: {dof_aktivitas}")

# 4. Bandingkan p-value dengan tingkat signifikansi 0.05 dan cetak kesimpulan
alpha = 0.05
print(f"\nTingkat signifikansi (alpha): {alpha}")

if p_value_aktivitas < alpha:
    print("Kesimpulan: Terdapat hubungan yang signifikan secara statistik antara Aktivitas Ekstrakurikuler dan Penempatan Kerja (Tolak H0).")
else:
    print("Kesimpulan: Tidak terdapat hubungan yang signifikan secara statistik antara Aktivitas Ekstrakurikuler dan Penempatan Kerja (Gagal Tolak H0).")

# --- Heatmap ---
plt.figure(figsize=(8,6))
sns.heatmap(contingency_table_aktivitas, annot=True, fmt='d', cmap="YlGnBu")
plt.title("Aktivitas Ekstrakurikuler vs Penempatan Kerja")
plt.xlabel("Penempatan Kerja")
plt.ylabel("Aktivitas Ekstrakurikuler")
plt.show()

# --- Stacked Bar Chart ---
contingency_table_aktivitas.plot(kind='bar', stacked=True, figsize=(10,6), colormap="viridis")
plt.title("Distribusi Penempatan Kerja berdasarkan Aktivitas Ekstrakurikuler")
plt.xlabel("Aktivitas Ekstrakurikuler")
plt.ylabel("Jumlah Alumni")
plt.xticks(rotation=45)
plt.legend(title="Penempatan Kerja")
plt.show()

"""## Analisis korelasi utama

### Subtask:
Tampilkan analisis deskriptif (rata-rata gaji) dan visualisasi box plot untuk membandingkan tingkat gaji berdasarkan Lokasi Geografis. Lakukan uji statistik (ANOVA atau uji t) jika memungkinkan untuk memverifikasi perbedaan rata-rata gaji antar lokasi secara statistik.

**Reasoning**:
Calculate and display the average salary per geographical location and then create a box plot to visualize the salary distribution across these locations.
"""

# 1. Hitung rata-rata gaji per Lokasi Geografis
average_gaji_per_lokasi = df.groupby('Lokasi Geografis')['Gaji'].mean().sort_values(ascending=False)

print("\n--- Rata-rata Gaji per Lokasi Geografis ---")
display(average_gaji_per_lokasi)

# 2. Buat box plot untuk visualisasi distribusi gaji per Lokasi Geografis
plt.figure(figsize=(12, 8))
sns.boxplot(data=df, x="Lokasi Geografis", y="Gaji", palette='viridis')
plt.title('Distribusi Gaji Alumni per Lokasi Geografis', fontsize=16)
plt.xlabel('Lokasi Geografis', fontsize=12)
plt.ylabel('Gaji', fontsize=12)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.show()

"""**Reasoning**:
Identify if there are more than two unique geographical locations, prepare the data for ANOVA if needed, and perform the ANOVA test to compare average salaries across locations, printing the results and conclusion.


"""

# 3. Identifikasi jumlah lokasi geografis unik
unique_locations = df['Lokasi Geografis'].nunique()
print(f"\n--- Analisis Statistik Gaji per Lokasi Geografis ---")
print(f"Jumlah lokasi geografis unik: {unique_locations}")

# 4. Jika ada lebih dari dua lokasi, persiapkan data untuk ANOVA
if unique_locations > 2:
    # Ekstrak gaji untuk setiap grup lokasi geografis
    location_groups = [df['Gaji'][df['Lokasi Geografis'] == loc].dropna() for loc in df['Lokasi Geografis'].unique()]

    # 5. Lakukan uji ANOVA (atau Kruskal-Wallis jika asumsi ANOVA tidak terpenuhi)
    # Check for normality assumption (optional but good practice) and homogeneity of variances (Levene test).
    # For simplicity and given the dummy nature of data, we will proceed with ANOVA.
    # If data were real and did not meet assumptions, Kruskal-Wallis could be used:
    # from scipy.stats import kruskal
    # stat, p_value_loc = kruskal(*location_groups)

    from scipy.stats import f_oneway
    stat, p_value_loc = f_oneway(*location_groups)

    # 6. Cetak hasil uji statistik dan kesimpulan
    print("\nHasil Uji ANOVA:")
    print(f"F-statistic: {stat}")
    print(f"P-value: {p_value_loc}")

    alpha = 0.05
    print(f"\nTingkat signifikansi (alpha): {alpha}")

    if p_value_loc < alpha:
        print("Kesimpulan: Terdapat perbedaan yang signifikan secara statistik pada rata-rata gaji antar lokasi geografis (Tolak H0).")
    else:
        print("Kesimpulan: Tidak terdapat perbedaan yang signifikan secara statistik pada rata-rata gaji antar lokasi geografis (Gagal Tolak H0).")

print("\n--- Visualisasi Gaji per Lokasi Geografis ---")

# 1. Boxplot
plt.figure(figsize=(10,6))
sns.boxplot(data=df, x='Lokasi Geografis', y='Gaji', palette='viridis')
plt.title("Distribusi Gaji per Lokasi Geografis")
plt.xticks(rotation=45)
plt.ylabel("Gaji")
plt.xlabel("Lokasi Geografis")
plt.show()

# 2. Barplot dengan error bar
plt.figure(figsize=(10,6))
sns.barplot(data=df, x='Lokasi Geografis', y='Gaji', estimator='mean', ci='sd', palette='viridis')
plt.title("Rata-rata Gaji per Lokasi Geografis (dengan Std Dev)")
plt.xticks(rotation=45)
plt.ylabel("Rata-rata Gaji")
plt.xlabel("Lokasi Geografis")
plt.show()

"""## Analisis statistik tambahan

### Subtask:
Lakukan analisis deskriptif lanjutan untuk variabel numerik kunci (Gaji, Tahun Angkatan, Relevansi Kurikulum, IPK, Masa Tunggu Kerja) dengan menampilkan statistik ringkasan dan visualisasi distribusi.

**Reasoning**:
Display descriptive statistics for the selected numerical columns and create visualizations for their distributions.
"""

# 1. Pilih kolom numerik kunci
numerical_cols = ['Gaji', 'Tahun Angkatan', 'Relevansi Kurikulum', 'IPK', 'Masa Tunggu Kerja']

# 2. Tampilkan statistik deskriptif
print("--- Statistik Deskriptif Kolom Numerik Kunci ---")
display(df[numerical_cols].describe())

# 3. Buat visualisasi distribusi untuk setiap kolom numerik kunci
print("\n--- Visualisasi Distribusi Kolom Numerik Kunci ---")
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.histplot(data=df, x=col, kde=True)
    plt.title(f'Distribusi {col}', fontsize=14)
    plt.xlabel(col, fontsize=10)
    plt.ylabel('Frekuensi', fontsize=10)
    plt.tight_layout()
    plt.show()

    plt.figure(figsize=(8, 3))
    sns.boxplot(data=df, x=col)
    plt.title(f'Box Plot {col}', fontsize=14)
    plt.xlabel(col, fontsize=10)
    plt.tight_layout()
    plt.show()

"""## Analisis statistik tambahan

### Subtask:
Lakukan analisis cluster (K-Means) pada variabel numerik kunci untuk mengidentifikasi segmen alumni.

**Reasoning**:
Standardize the selected numerical variables and perform K-Means clustering with k=4, then add the cluster labels to the original DataFrame. Finally, display the descriptive statistics for each cluster to understand their characteristics.
"""

# 1. Pilih variabel numerik kunci untuk clustering
numerical_cols_clustering = ['Gaji', 'Tahun Angkatan', 'Relevansi Kurikulum', 'IPK', 'Masa Tunggu Kerja']
df_clustering = df[numerical_cols_clustering].copy()

# 2. Lakukan standardisasi data
scaler = StandardScaler()
df_scaled = scaler.fit_transform(df_clustering)
df_scaled = pd.DataFrame(df_scaled, columns=numerical_cols_clustering) # Convert back to DataFrame

# 3. Tentukan jumlah cluster (k)
k = 4 # Menggunakan k=4 sesuai instruksi

# 4. Inisialisasi model K-Means
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10) # n_init='auto' or specify number

# 5. Fit model K-Means pada data yang sudah distandardisasi
kmeans.fit(df_scaled)

# 6. Tambahkan label cluster ke DataFrame asli
df['Cluster Label'] = kmeans.labels_

# 7. Tampilkan ringkasan statistik untuk setiap cluster
print("\n--- Ringkasan Statistik per Cluster ---")
cluster_summary = df.groupby('Cluster Label')[numerical_cols_clustering].mean()
display(cluster_summary)

# Visualisasi ringkasan statistik per cluster
print("\n--- Visualisasi Ringkasan Statistik per Cluster ---")
for col in numerical_cols_clustering:
    plt.figure(figsize=(10, 6))
    sns.barplot(x=cluster_summary.index, y=cluster_summary[col], palette='viridis')
    plt.title(f'Rata-rata {col} per Cluster', fontsize=14)
    plt.xlabel('Cluster Label', fontsize=12)
    plt.ylabel(f'Rata-rata {col}', fontsize=12)
    plt.xticks(rotation=0)
    plt.tight_layout()
    plt.show()

"""## Analisis statistik tambahan

### Subtask:
Lakukan analisis sentimen pada kolom 'Umpan Balik' untuk mengklasifikasikan umpan balik menjadi kategori (misalnya: Positif, Negatif, Netral) dan tampilkan distribusinya.

**Reasoning**:
Define a function for sentiment analysis on the 'Umpan Balik' column using a simple keyword-based approach, apply it to create a new 'Sentiment' column, calculate the frequency and percentage distribution of sentiment labels, and display the results.
"""

# 1. Definisikan fungsi analisis sentimen sederhana
def analyze_sentiment(feedback):
    feedback_lower = feedback.lower()
    if "tingkatkan" in feedback_lower or "perbanyak" in feedback_lower or "perlu diperbarui" in feedback_lower or "perlu ada" in feedback_lower:
        return "Neutral" # These suggest areas for improvement but aren't explicitly negative
    elif "baik" in feedback_lower or "bagus" in feedback_lower or "membantu" in feedback_lower or "bermanfaat" in feedback_lower:
         return "Positive"
    # For this dummy data, we assume other feedbacks are neutral or not explicitly negative
    else:
        return "Neutral"

# 2. Terapkan fungsi ke kolom 'Umpan Balik'
df['Sentiment'] = df['Umpan Balik'].apply(analyze_sentiment)

# 3. Hitung jumlah kemunculan setiap kategori sentimen
sentiment_counts = df['Sentiment'].value_counts()

# 4. Hitung persentase kemunculan setiap kategori sentimen
sentiment_percentages = df['Sentiment'].value_counts(normalize=True) * 100

# 5. Tampilkan tabel frekuensi dan persentase
sentiment_distribution = pd.DataFrame({
    'Frequency': sentiment_counts,
    'Percentage (%)': sentiment_percentages
})

print("\n--- Distribusi Sentimen Umpan Balik Alumni ---")
display(sentiment_distribution)

# Optional: Display some examples for each sentiment
print("\n--- Contoh Umpan Balik Netral ---")
display(df[df['Sentiment'] == 'Neutral']['Umpan Balik'].sample(min(3, len(df[df['Sentiment'] == 'Neutral'])), random_state=42))

print("\n--- Contoh Umpan Balik Positif ---")
display(df[df['Sentiment'] == 'Positive']['Umpan Balik'].sample(min(3, len(df[df['Sentiment'] == 'Positive'])), random_state=42))

# Buat grafik batang untuk visualisasi distribusi sentimen
plt.figure(figsize=(8, 6))
sns.barplot(x=sentiment_distribution.index, y=sentiment_distribution['Percentage (%)'], palette='viridis', hue=sentiment_distribution.index, legend=False)
plt.title('Persentase Alumni per Sentimen Umpan Balik', fontsize=16)
plt.xlabel('Sentimen', fontsize=12)
plt.ylabel('Persentase (%)', fontsize=12)
plt.ylim(0, 100) # Batasi sumbu y dari 0 hingga 100%
plt.tight_layout()
plt.show()

"""## **Ringkasan Temuan Kunci dari Analisis Data Tracer Alumni**

Berdasarkan analisis data tracer alumni Teknik Elektro, ditemukan beberapa pola dan insight utama:

1.  **Distribusi Alumni:** Data mencakup alumni dari berbagai tahun angkatan (2016-2024) dengan distribusi yang relatif merata di lima konsentrasi studi. Sebaran geografis alumni cukup luas di berbagai kota besar di Indonesia.
2.  **Karir Alumni:** Alumni bekerja di berbagai bidang industri, dengan sektor IT, Otomotif, dan Energi menjadi penyerap terbanyak. Posisi/jabatan yang banyak dipegang meliputi HSE Officer, PLC Programmer, dan berbagai peran engineer.
3.  **Gaji:** Rata-rata gaji alumni sekitar Rp 6.46 Juta. Analisis statistik (ANOVA) menunjukkan **tidak ada perbedaan yang signifikan secara statistik** pada rata-rata gaji antar lokasi geografis alumni dalam dataset ini (p-value = 0.220).
4.  **Masa Tunggu Kerja & IPK:** Terdapat **hubungan negatif yang signifikan secara statistik** antara IPK dan Masa Tunggu Kerja (p-value < 0.0001). Alumni dengan IPK lebih tinggi cenderung memiliki masa tunggu kerja yang lebih pendek.
5.  **Pengalaman Magang & Penempatan Kerja:** Terdapat **hubungan yang signifikan secara statistik** antara Pengalaman Magang dan Penempatan Kerja (p-value < 0.0001). Alumni dengan pengalaman magang memiliki peluang lebih tinggi untuk segera mendapatkan penempatan kerja.
6.  **Aktivitas Ekstrakurikuler & Penempatan Kerja:** Dalam data ini, **tidak ditemukan hubungan yang signifikan secara statistik** antara partisipasi dalam Aktivitas Ekstrakurikuler dan status Penempatan Kerja (p-value = 0.136).
7.  **Konsentrasi Studi & Bidang Industri:** Hasil analisis (Chi-Square) menunjukkan **tidak terdapat hubungan yang signifikan secara statistik** antara Konsentrasi Studi yang diambil alumni dan Bidang Industri tempat mereka bekerja (p-value = 0.9578). Ini bisa mengindikasikan fleksibilitas karir alumni atau perluasan relevansi kurikulum di berbagai sektor.
8.  **Klaster Alumni:** Analisis klaster mengidentifikasi segmen-segmen alumni yang berbeda berdasarkan kombinasi faktor numerik seperti Gaji, Tahun Angkatan, IPK, Relevansi Kurikulum, dan Masa Tunggu Kerja. Ini dapat membantu memahami profil alumni yang berbeda (misalnya: alumni baru dengan gaji awal vs. alumni berpengalaman dengan gaji lebih tinggi).
9.  **Sentimen Umpan Balik:** Sentimen umpan balik alumni pada data dummy ini didominasi oleh kategori Netral (88%), yang seringkali berisi saran untuk perbaikan kurikulum atau program. Sebagian kecil bersifat Positif (12%), dan tidak ada umpan balik Negatif eksplisit yang terdeteksi oleh metode analisis sentimen sederhana.


## **Insight & Rekomendasi Kebijakan Awal**

Berdasarkan temuan di atas, berikut adalah beberapa insight dan rekomendasi awal yang dapat dipertimbangkan oleh pihak universitas/fakultas/program studi:

1.  **Fokus pada Peningkatan IPK dan Program Magang:** Mengingat signifikansi statistik antara IPK dengan masa tunggu kerja dan pengalaman magang dengan penempatan kerja, universitas perlu memperkuat program akademik untuk mendukung pencapaian IPK tinggi serta memperluas dan meningkatkan kualitas program magang/kerja praktik. Kerjasama dengan industri perlu diintensifkan untuk menciptakan peluang magang yang lebih banyak dan relevan.
2.  **Fleksibilitas Karir Lulusan & Kurikulum:** Temuan bahwa konsentrasi studi tidak berkorelasi signifikan dengan bidang industri kerja menunjukkan bahwa kurikulum saat ini mungkin sudah cukup relevan untuk berbagai sektor atau lulusan memiliki adaptabilitas yang tinggi. Namun, ini juga bisa diartikan perlunya penyesuaian atau pembaruan kurikulum agar lebih selaras dengan kebutuhan spesifik industri atau tren teknologi terbaru sesuai masukan dari umpan balik alumni.
3.  **Pemanfaatan Data Klaster:** Mengidentifikasi klaster alumni dapat membantu universitas merancang program pembinaan karir yang lebih tepat sasaran (misalnya: program pengembangan skill tambahan untuk klaster alumni dengan masa tunggu kerja lebih lama, atau forum berbagi pengalaman untuk klaster alumni berkarir sukses).
4.  **Tindak Lanjut Umpan Balik Netral:** Mayoritas umpan balik bersifat Netral dan berisi saran perbaikan. Analisis mendalam terhadap konten umpan balik ini (meskipun pada data dummy) sangat penting untuk mengidentifikasi area kurikulum atau layanan kemahasiswaan yang paling memerlukan perhatian (misalnya: perbanyak praktikum, tambahkan materi ML, perbarui materi 5G, dll.).
5.  **Analisis Lebih Lanjut:** Meskipun tidak ada perbedaan gaji signifikan berdasarkan lokasi geografis dalam data ini, analisis lebih rinci diperlukan pada data riil, termasuk mempertimbangkan faktor lain seperti pengalaman kerja, tipe perusahaan, dan inflasi antar daerah.
6.  **Peran Aktivitas Ekstrakurikuler:** Temuan non-signifikan terkait aktivitas ekstrakurikuler dan penempatan kerja perlu dikaji lebih lanjut. Mungkin ada faktor lain (seperti jenis aktivitas, peran kepemimpinan, atau skill spesifik yang diasah) yang berkorelasi lebih kuat dengan kesuksesan karir, atau dataset dummy ini tidak sepenuhnya mencerminkan realitas.
"""